# ==================================================================================================
# å¸§ç²¾ç¡®è§†é¢‘åˆæˆå™¨ V2
#
# åŠŸèƒ½æè¿°:
# æœ¬è„šæœ¬å®šä¹‰äº† `FrameAccurateVideoComposerV2` ç±»ï¼Œæ˜¯ä¸€ä¸ªç”¨äºæ ¹æ®ç»“æ„åŒ–çš„ JSON è¾“å…¥
# ä»¥ç¼–ç¨‹æ–¹å¼åˆ›å»ºè§†é¢‘çš„å¼ºå¤§å·¥å…·ã€‚å®ƒæ“…é•¿å°†è§†é¢‘ç‰‡æ®µä»¥å¸§çº§åˆ«çš„ç²¾åº¦æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œä»¥åŒ¹é…é¢„å®šä¹‰çš„æ—¶é•¿ã€‚
#
# ä¸»è¦ç‰¹æ€§:
# - JSONé©±åŠ¨ç»“æ„: é€šè¿‡JSONæ–‡ä»¶å®šä¹‰è§†é¢‘æ„æˆï¼ŒæŒ‡æ˜æ®µè½ã€åœºæ™¯å’Œç´ æè·¯å¾„ã€‚
# - å¸§ç²¾ç¡®è®¡æ—¶: æ ¹æ®ç›®æ ‡æ—¶é•¿ç²¾ç¡®è®¡ç®—å¹¶ä¸ºæ¯ä¸ªåœºæ™¯åˆ†é…å¸§æ•°ï¼Œç¡®ä¿æ®µè½çš„æ—¶é•¿ç²¾ç¡®æ— è¯¯ã€‚
# - åŠ¨æ€ç´ ææ—¶é•¿: ä½¿ç”¨ `ffprobe` è·å–è§†é¢‘ç´ æçš„çœŸå®æ—¶é•¿ï¼Œç”¨äºç²¾ç¡®è®¡ç®—ã€‚
# - GPUåŠ é€Ÿ: è‡ªåŠ¨æ£€æµ‹å¹¶åˆ©ç”¨NVIDIA (NVENC) ç¡¬ä»¶åŠ é€Ÿè¿›è¡ŒFFmpegç¼–ç ï¼Œå¹¶å¯å›é€€åˆ°CPUã€‚
# - é”™è¯¯å¤„ç†ä¸æ¢å¤: åŒ…å«ä¸¥æ ¼æ¨¡å¼ï¼Œå¯åœ¨å¤±è´¥æ—¶ä¸­æ­¢æµç¨‹ï¼Œå¹¶æä¾›å…ˆè¿›çš„è¯Šæ–­ä¸æ¢å¤æœºåˆ¶ï¼Œ
#   ç”¨ä»¥è¯†åˆ«å’Œæ›¿æ¢å¯¼è‡´FFmpegå¤±è´¥çš„æŸåè§†é¢‘ç´ æã€‚
# - éŸ³é¢‘åŒæ­¥: å°†æœ€ç»ˆçš„è§†é¢‘ä¸ä¸»éŸ³è½¨åˆå¹¶ã€‚å¦‚æœè§†é¢‘æ¯”éŸ³é¢‘çŸ­ï¼Œå®ƒä¼šç”¨é»‘å±å¡«å……è§†é¢‘ä»¥åŒ¹é…éŸ³é¢‘çš„é•¿åº¦ã€‚
# - å¹¶å‘å¤„ç†: ä½¿ç”¨ `ThreadPoolExecutor` åŠ å¿«è·å–è§†é¢‘æ—¶é•¿çš„è¿‡ç¨‹ã€‚
# - æ¨¡å—åŒ–ä¸å¯é…ç½®: è®¾è®¡ä¸ºå¤§å‹ç³»ç»Ÿçš„ä¸€éƒ¨åˆ†ï¼Œå¯é…ç½®åˆ†è¾¨ç‡ã€å¸§ç‡ã€ä¸´æ—¶ç›®å½•ç­‰å‚æ•°ã€‚
# ==================================================================================================

import json
import subprocess
from tqdm import tqdm
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
from time import sleep
import os
import shutil
from src.core.asset_manager import AssetManager
from src.config_loader import config
from src.logger import log
from src.utils import run_command
# from ..utils import get_terminal_width_by_ratio
from os.path import basename


class FrameAccurateVideoComposerV2:
    def __init__(
        self,
        task_id,
        video_struct_path,
        input_audio_path,
        output_video_path,
        temp_dir="temp_segments",
        resolution=(1920, 1080),
        fps=30,
        trim_audio=True,
        silent=True,
        strict_mode=True,
        max_workers=8
    ):
        """
        âœ… åˆå§‹åŒ–é…ç½®å‚æ•°
        :param task_id: å½“å‰ä»»åŠ¡çš„ID
        :param video_struct_path: è§†é¢‘ç»“æ„ JSON æ–‡ä»¶è·¯å¾„ï¼ˆå«ç‰‡æ®µå’Œç´ æåˆ—è¡¨ï¼‰
        :param input_audio_path: åˆå¹¶ç”¨éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        :param output_video_path: æœ€ç»ˆè¾“å‡ºè§†é¢‘è·¯å¾„
        :param temp_dir: å­˜å‚¨ä¸­é—´æ®µè½è§†é¢‘çš„ç›®å½•
        :param resolution: è¾“å‡ºè§†é¢‘åˆ†è¾¨ç‡ï¼Œé»˜è®¤ 1920x1080
        :param fps: è¾“å‡ºè§†é¢‘å¸§ç‡ï¼Œé»˜è®¤ 30
        :param trim_audio: æ˜¯å¦æ ¹æ®æ€»è§†é¢‘æ—¶é•¿è£å‰ªéŸ³é¢‘
        :param silent: æ˜¯å¦é™é»˜è¿è¡Œ FFmpegï¼ˆä¸æ‰“å°è¿‡ç¨‹ï¼‰
        :param strict_mode: è‹¥ä»»ä¸€æ®µè½å¤±è´¥åˆ™ç»ˆæ­¢æµç¨‹
        :param max_workers: è·å–ç´ ææ—¶é•¿æ—¶ä½¿ç”¨çš„æœ€å¤§çº¿ç¨‹æ•°
        """
        self.task_id = task_id
        self.video_struct_path = Path(video_struct_path)
        self.input_audio_path = Path(input_audio_path)
        self.output_video_path = Path(output_video_path)
        self.temp_dir = Path(temp_dir)
        self.width, self.height = resolution
        self.fps = fps
        self.trim_audio = trim_audio
        self.silent = silent
        self.strict_mode = strict_mode
        self.max_workers = max_workers
        self.structure = []
        self.gpu_enabled = self.check_gpu_support()

    def load_structure(self):
        """ğŸ“¦ åŠ è½½ JSON è§†é¢‘ç»“æ„ä¿¡æ¯"""
        with open(self.video_struct_path, "r", encoding="utf-8") as f:
            self.structure = json.load(f)

    def check_gpu_support(self):
        """ğŸ” åŠ¨æ€æ£€æŸ¥ FFmpeg æ˜¯å¦æ”¯æŒ NVIDIA NVENC ç¡¬ä»¶åŠ é€Ÿ"""
        try:
            result = run_command(["ffmpeg", "-encoders"], "Failed to check ffmpeg encoders.")
            if "h264_nvenc" in result.stdout:
                log.info("âœ… NVIDIA GPU acceleration (h264_nvenc) detected. Hardware acceleration will be enabled.")
                return True
            else:
                log.info("â„¹ï¸ NVIDIA GPU acceleration not detected. Encoding will use CPU.")
                return False
        except RuntimeError as e:
            log.warning(f"âš ï¸ Could not check for GPU support, proceeding with CPU. Reason: {e}")
            return False

    def get_duration(self, path):
        """â±ï¸ è·å–ç´ æçš„çœŸå®æ—¶é•¿ï¼ˆä½¿ç”¨ ffprobeï¼‰ï¼Œè¿”å›é«˜ç²¾åº¦æµ®ç‚¹æ•°"""
        cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "default=noprint_wrappers=1:nokey=1",
            str(path)
        ]
        try:
            result = run_command(cmd, f"Failed to get duration for {path}")
            return float(result.stdout.strip())
        except (RuntimeError, ValueError):
            return 0.0

    def process_segment(self, segment, seg_index):
        """ğŸ¬ åŸºäºå¸§æ•°åˆ†é…æ®µè½æ—¶é•¿ï¼Œç”Ÿæˆæ®µè½è§†é¢‘ï¼Œç¡®ä¿é›¶è¯¯å·®"""
        scenes = segment.get("scenes", [])

        # æ£€æŸ¥åœºæ™¯åˆ—è¡¨æ˜¯å¦ä¸ºç©º
        if not scenes:
            raise ValueError(f"Data integrity error: Segment {seg_index:02d} contains no scenes. Processing cannot continue.")

        target_duration = segment["duration"]
        asset_paths = [scene["asset_path"] for scene in scenes]

        # éªŒè¯æ¯ä¸ªåœºæ™¯éƒ½åŒ…å«æœ‰æ•ˆçš„ 'time' å­—æ®µ
        for i, scene in enumerate(scenes):
            if "time" not in scene or not isinstance(scene["time"], (int, float)) or scene["time"] <= 0:
                raise ValueError(f"âŒ Scene {i} is missing a valid 'time' field â†’ {scene.get('asset_path')}")

        # è®¡ç®—ç›®æ ‡æ—¶é•¿æ‰€éœ€çš„æ€»å¸§æ•°
        target_total_frames = int(round(target_duration * self.fps))
        
        # å¹¶å‘è·å–æ¯ä¸ªç´ ææ–‡ä»¶çš„å®é™…æ—¶é•¿
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            real_durations = list(tqdm(executor.map(self.get_duration, asset_paths),
                                    total=len(scenes),
                                    desc=f"â±ï¸ Getting asset durations for Segment {seg_index:02d}"))
        for scene, real_dur in zip(scenes, real_durations):
            scene["real_duration"] = real_dur

        # æ ¹æ®æ¯ä¸ªåœºæ™¯çš„ 'time' æ¯”ä¾‹ï¼Œåœ¨åœºæ™¯é—´åˆ†é…æ€»å¸§æ•°
        total_time_ratio = sum(scene["time"] for scene in scenes)
        allocated_frames_sum = 0
        for i, scene in enumerate(scenes):
            if i == len(scenes) - 1:
                # å°†å‰©ä½™çš„å¸§åˆ†é…ç»™æœ€åä¸€ä¸ªåœºæ™¯ï¼Œä»¥é¿å…èˆå…¥è¯¯å·®
                scene["allocated_frames"] = target_total_frames - allocated_frames_sum
            else:
                ratio = scene["time"] / total_time_ratio
                frames = int(round(ratio * target_total_frames))
                scene["allocated_frames"] = frames
                allocated_frames_sum += frames
        
        # è®¡ç®—æ¯ä¸ªåœºæ™¯åˆ†é…åˆ°çš„æ—¶é•¿
        for scene in scenes:
            scene["allocated_duration"] = scene["allocated_frames"] / self.fps

        input_args, filter_lines, concat_labels = [], [], []
        for idx, scene in enumerate(scenes):
            input_args += ["-i", scene["asset_path"]]
            
            frames = scene["allocated_frames"]
            v_label = f"v{idx}"
            
            base_filter = (f"[{idx}:v]scale={self.width}:{self.height}:force_original_aspect_ratio=decrease,"
                           f"pad={self.width}:{self.height}:(ow-iw)/2:(oh-ih)/2,setsar=1,fps={self.fps}")

            pad_filter = ""
            allocated_duration = frames / self.fps
            real_duration = scene.get("real_duration", 0)
            if allocated_duration > real_duration and real_duration > 0:
                pad_duration = allocated_duration - real_duration
                pad_filter = f",tpad=stop_mode=clone:stop_duration={pad_duration}"

            trim_and_pts_filter = f",select='between(n,0,{frames-1})',setpts=PTS-STARTPTS[{v_label}];"
            
            filter_lines.append(base_filter + pad_filter + trim_and_pts_filter)
            concat_labels.append(f"[{v_label}]")

            origin = scene["time"]
            allocated = scene["allocated_duration"]
            compensated = round(allocated - origin, 3)
            print(f"ğŸï¸ {basename(scene['asset_path'])} â†’ Original:{origin}s, Compensated:{compensated}s, Calculated:{allocated:.3f}s ({frames} frames)")

        filter_complex = "".join(filter_lines)
        filter_complex += f"{''.join(concat_labels)}concat=n={len(scenes)}:v=1:a=0[outv]"

        output_path = self.temp_dir / f"segment_{seg_index:02d}.mp4"

        if output_path.exists() and output_path.stat().st_size > 1024:
            print(f"âœ… Segment {seg_index:02d} already exists, skipping generation.")
            return (output_path, target_total_frames)
        
        encoder_opts = []
        if self.gpu_enabled:
            encoder_opts = ["-c:v", "h264_nvenc", "-preset", "p7", "-tune", "hq", "-rc", "vbr", "-cq", "23"]
        else:
            encoder_opts = ["-c:v", "libx264", "-crf", "23", "-preset", "ultrafast"]

        ffmpeg_cmd = ["ffmpeg"] + input_args + [
            "-filter_complex", filter_complex,
            "-map", "[outv]",
        ] + encoder_opts + [
            "-pix_fmt", "yuv420p",
            "-threads", "4", 
            "-y", str(output_path)
        ]

        run_command(
            ffmpeg_cmd,
            f"Failed to process segment {seg_index}",
            capture_output=self.silent, # ä»…åœ¨é™é»˜æ¨¡å¼ä¸‹æ•è·è¾“å‡º
        )

        if not output_path.exists() or output_path.stat().st_size < 1024:
            print(f"\nğŸ§¨ Segment {seg_index:02d} generation failed â†’ {output_path}")
            for path in asset_paths:
                print(f"  ğŸ“„ Source asset: {path}")
            if self.strict_mode:
                raise RuntimeError(f"âŒ Strict mode engaged: Segment {seg_index:02d} video generation failed")
            return None
        
        real_output_duration = self.get_duration(output_path)
        real_output_frames = int(round(real_output_duration * self.fps))
        frame_diff = real_output_frames - target_total_frames
        
        planned_duration_str = f"{target_total_frames / self.fps:.3f}s"
        real_duration_str = f"{real_output_duration:.3f}s"
        
        print(f"ğŸ“Š Segment {seg_index:02d}: Planned {target_total_frames} frames ({planned_duration_str}), Generated {real_output_frames} frames ({real_duration_str}), Frame difference: {frame_diff:+} frames\n")

        return (output_path, target_total_frames)

    def _test_scene_combination(self, scenes_to_test: list, output_filename: str) -> bool:
        """æµ‹è¯•ä¸€ç»„åœºæ™¯æ˜¯å¦å¯ä»¥æˆåŠŸåˆå¹¶"""
        if not scenes_to_test:
            return True
        
        input_args, filter_lines, concat_labels = [], [], []
        total_frames = 0

        for idx, scene in enumerate(scenes_to_test):
            input_args += ["-i", scene["asset_path"]]
            frames = scene["allocated_frames"]
            total_frames += frames
            v_label = f"v{idx}"
            
            base_filter = (f"[{idx}:v]scale={self.width}:{self.height}:force_original_aspect_ratio=decrease,"
                           f"pad={self.width}:{self.height}:(ow-iw)/2:(oh-ih)/2,setsar=1,fps={self.fps}")
            
            pad_filter = ""
            allocated_duration = frames / self.fps
            real_duration = scene.get("real_duration", 0)
            if allocated_duration > real_duration and real_duration > 0:
                pad_duration = allocated_duration - real_duration
                pad_filter = f",tpad=stop_mode=clone:stop_duration={pad_duration}"

            trim_and_pts_filter = f",select='between(n,0,{frames-1})',setpts=PTS-STARTPTS[{v_label}];"
            
            filter_lines.append(base_filter + pad_filter + trim_and_pts_filter)
            concat_labels.append(f"[{v_label}]")

        filter_complex = "".join(filter_lines)
        filter_complex += f"{''.join(concat_labels)}concat=n={len(scenes_to_test)}:v=1:a=0[outv]"

        output_path = self.temp_dir / output_filename
        
        encoder_opts = ["-c:v", "libx264", "-crf", "23", "-preset", "ultrafast"]
        if self.gpu_enabled:
            encoder_opts = ["-c:v", "h264_nvenc", "-preset", "p7", "-tune", "hq", "-rc", "vbr", "-cq", "23"]

        ffmpeg_cmd = ["ffmpeg"] + input_args + [
            "-filter_complex", filter_complex,
            "-map", "[outv]",
        ] + encoder_opts + [
            "-pix_fmt", "yuv420p",
            "-threads", "4", 
            "-y", str(output_path)
        ]

        try:
            result = run_command(
                ffmpeg_cmd,
                f"Diagnostic test failed for {output_filename}",
                capture_output=True # ä¸ºè¯Šæ–­å§‹ç»ˆæ•è·è¾“å‡º
            )
        except RuntimeError as e:
            log.debug(f"Test combination failed. FFmpeg command failed: {e}")
            if output_path.exists():
                os.remove(output_path)
            return False
        
        if not output_path.exists() or output_path.stat().st_size < 1024:
            log.debug(f"Test combination failed. FFmpeg stderr:\n{result.stderr}")
            if output_path.exists():
                os.remove(output_path)
            return False
        
        if output_path.exists():
            os.remove(output_path)
        return True

    def _replace_asset_for_scene(self, scene: dict) -> bool:
        """ä¸ºæœ‰é—®é¢˜çš„åœºæ™¯æ›¿æ¢ç´ æ"""
        log.info(f"  -> Replacing asset for scene: {scene.get('asset_path')}")
        try:
            asset_manager = AssetManager(config, self.task_id)
            online_search_count = config.get('asset_search', {}).get('online_search_count', 10)
        except Exception as e:
            log.error(f"  -> Replacement failed: Could not initialize AssetManager. Error: {e}")
            return False

        old_asset_path = scene.get('asset_path')
        found_video_info_list = asset_manager.find_assets_for_scene(scene, online_search_count)
        
        if not found_video_info_list:
            log.error(f"  -> Could not find a replacement asset.")
            return False

        new_asset_path = found_video_info_list[0].get('local_path')
        if not new_asset_path or not os.path.exists(new_asset_path):
            log.error(f"  -> AssetManager returned an invalid new asset path.")
            return False

        try:
            if os.path.exists(old_asset_path):
                os.remove(old_asset_path)
            shutil.move(new_asset_path, old_asset_path)
            log.success(f"  -> Successfully replaced asset, moving '{new_asset_path}' to '{old_asset_path}'")
            return True
        except Exception as e:
            log.error(f"  -> File replacement operation failed: {e}")
            return False

    def _handle_segment_failure(self, segment: dict, seg_index: int) -> bool:
        """å¤„ç†å¤±è´¥çš„æ®µè½ï¼Œè¿›è¡Œè¯Šæ–­å’Œæ¢å¤"""
        log.warning(f"Entering diagnostic and recovery mode for failed Segment {seg_index}...")
        scenes = segment.get("scenes", [])
        if len(scenes) <= 1:
            log.warning("Segment contains only one or zero scenes, attempting direct replacement.")
            if scenes and self._replace_asset_for_scene(scenes[0]):
                return True
            return False

        while True:
            good_scenes = []
            found_faulty = False
            for i, scene in enumerate(scenes):
                log.info(f"  -> Diagnostic test: Combining scene {i+1}/{len(scenes)}...")
                test_combination = good_scenes + [scene]
                
                if not self._test_scene_combination(test_combination, f"diag_test_{seg_index}.mp4"):
                    log.error(f"  -> Faulty asset identified: Scene {i} ({scene.get('asset_path')})")
                    found_faulty = True
                    
                    if not self._replace_asset_for_scene(scene):
                        log.error("  -> Asset replacement failed, aborting recovery for this segment.")
                        return False
                    
                    # ç´ ææ›¿æ¢æˆåŠŸåï¼Œéœ€è¦é‡æ–°è·å–å®ƒçš„çœŸå®æ—¶é•¿
                    new_duration = self.get_duration(scene['asset_path'])
                    scene['real_duration'] = new_duration

                    log.info("  -> Asset replaced successfully. Re-validating the entire segment from the beginning.")
                    break
                else:
                    good_scenes.append(scene)
            
            if not found_faulty:
                log.success(f"Diagnosis complete: All assets in Segment {seg_index} are compatible. Recovery successful.")
                return True

    def combine_segments(self, segment_results, audio_duration):
        """ğŸ“½ï¸ V2: ä½¿ç”¨ concat æ»¤é•œåˆå¹¶æ‰€æœ‰æ®µè½ï¼Œå¹¶ç”¨ tpad æ»¤é•œç¡®ä¿è§†é¢‘ä¸éŸ³é¢‘åŒé•¿"""
        valid_segment_results = [r for r in segment_results if r and r[0] and r[0].exists() and r[0].stat().st_size > 1024]
        if not valid_segment_results:
            raise RuntimeError("âŒ No valid segments available to combine.")

        input_args = []
        concat_labels = []
        for i, result in enumerate(valid_segment_results):
            input_args.extend(["-i", str(result[0])])
            concat_labels.append(f"[{i}:v]")

        # è®¡ç®—è§†é¢‘æ€»æ—¶é•¿å’Œéœ€è¦å¡«å……çš„é»‘åœºæ—¶é•¿
        total_video_duration = sum(self.get_duration(r[0]) for r in valid_segment_results)
        padding_duration = audio_duration - total_video_duration
        
        filter_complex_parts = [
            f"{''.join(concat_labels)}concat=n={len(valid_segment_results)}:v=1:a=0[v_concat];"
        ]

        # åªæœ‰åœ¨è§†é¢‘æ¯”éŸ³é¢‘çŸ­çš„æƒ…å†µä¸‹æ‰æ·»åŠ  tpad æ»¤é•œ
        if padding_duration > 0:
            log.warning(f"ğŸ“¹ Video duration ({total_video_duration:.3f}s) is shorter than audio ({audio_duration:.3f}s). Padding with {padding_duration:.3f}s of black screen.")
            # ä½¿ç”¨ tpad æ»¤é•œåœ¨è§†é¢‘æœ«å°¾æ·»åŠ é»‘è‰²å¸§æ¥è¡¥è¶³æ—¶é•¿
            filter_complex_parts.append(f"[v_concat]tpad=stop_duration={padding_duration}:color=black[v_padded];")
            video_map_label = "[v_padded]"
        else:
            video_map_label = "[v_concat]"

        filter_complex = "".join(filter_complex_parts)
        
        # å°†éŸ³é¢‘ä½œä¸ºç‹¬ç«‹è¾“å…¥
        audio_input = ["-i", str(self.input_audio_path)]
        
        # æ„å»ºæœ€ç»ˆå‘½ä»¤
        ffmpeg_cmd = ["ffmpeg"] + input_args + audio_input + [
            "-filter_complex", filter_complex,
            "-map", video_map_label,
            "-map", f"{len(valid_segment_results)}:a", # éŸ³é¢‘æ˜¯æœ€åä¸€ä¸ªè¾“å…¥
            "-c:v", "libx264", # è§†é¢‘æµéœ€è¦é‡æ–°ç¼–ç ä»¥åº”ç”¨æ»¤é•œ
            "-crf", "23",
            "-preset", "ultrafast",
            "-c:a", "aac",
            "-b:a", "192k",
            "-t", str(audio_duration), # V2.1 ä¿®æ­£: ä½¿ç”¨ -t ç²¾ç¡®æ§åˆ¶æœ€ç»ˆæ—¶é•¿
            "-y", str(self.output_video_path)
        ]
        
        if self.gpu_enabled:
            ffmpeg_cmd[ffmpeg_cmd.index("-c:v") + 1] = "h264_nvenc"
            ffmpeg_cmd[ffmpeg_cmd.index("-preset") + 1] = "p7"
            # ç§»é™¤æ—§çš„CRFï¼Œä¸ºNVENCæ’å…¥CQ
            ffmpeg_cmd.pop(ffmpeg_cmd.index("-crf") + 1)
            ffmpeg_cmd[ffmpeg_cmd.index("-crf")] = "-cq"
            ffmpeg_cmd.insert(ffmpeg_cmd.index("-cq") + 1, "23")


        print("\nğŸ”— Combining all segments using V2 filter chain...")
        try:
            run_command(
                ffmpeg_cmd,
                "Failed to combine segments",
                capture_output=self.silent,
            )
        except RuntimeError:
            log.error("FFmpeg combine process failed.")
        
        if self.output_video_path.exists() and self.output_video_path.stat().st_size > 0:
            final_video_duration = self.get_duration(self.output_video_path)
            duration_diff = final_video_duration - audio_duration
            
            print(f"\nâœ… Final Validation (V2):\n"
                  f"  - Target audio duration: {audio_duration:.3f}s\n"
                  f"  - Final video duration: {final_video_duration:.3f}s\n"
                  f"  - Duration difference: {duration_diff:+.3f}s")


    def execute(self):
        """ğŸ V2 æ‰§è¡Œæµç¨‹: ç§»é™¤é”™è¯¯çš„è§†é¢‘æ—¶é•¿å¯¹é½é€»è¾‘"""
        self.load_structure()
        self.temp_dir.mkdir(exist_ok=True)

        true_audio_duration = self.get_duration(self.input_audio_path)
        log.info(f"ğŸ”Š Target audio duration: {true_audio_duration:.3f}s")

        # V2 ä¿®æ­£: ç§»é™¤åœ¨ execute æ–¹æ³•ä¸­ä¿®æ”¹è§†é¢‘ç»“æ„çš„è¡Œä¸ºã€‚
        # æ—¶é•¿å¯¹é½åº”åœ¨æœ€ç»ˆåˆå¹¶æ—¶å¤„ç†ï¼Œè€Œä¸æ˜¯é€šè¿‡ä¿®æ”¹ç‰‡æ®µæ—¶é•¿ã€‚
        total_planned_video_duration = sum(seg["duration"] for seg in self.structure)
        log.info(f"ğŸï¸ Planned total video duration: {total_planned_video_duration:.3f}s")

        segment_results = []
        max_retries = 1 # æ¯ä¸ªæ®µè½çš„æœ€å¤§æ¢å¤å°è¯•æ¬¡æ•°
        print(f"\nğŸï¸ Found {len(self.structure)} video segments to process")
        for i, segment in enumerate(self.structure):
            print(f"\nğŸ¬ Processing Segment {i+1}/{len(self.structure)}")
            
            result = None
            for attempt in range(max_retries + 1):
                try:
                    result = self.process_segment(segment, i)
                    break # å¦‚æœæˆåŠŸï¼Œåˆ™è·³å‡ºé‡è¯•å¾ªç¯
                except Exception as e:
                    log.error(f"Failed to generate Segment {i} (Attempt {attempt + 1}/{max_retries + 1}). Error: {e}")
                    if attempt < max_retries and self.strict_mode is False:
                        recovery_successful = self._handle_segment_failure(segment, i)
                        if recovery_successful:
                            log.success(f"Recovery successful. Retrying Segment {i}...")
                            continue # ç»§ç»­ä¸‹ä¸€æ¬¡å°è¯•
                        else:
                            log.error(f"Recovery failed. Aborting processing for Segment {i}.")
                            result = None # æ ‡è®°ä¸ºå¤±è´¥
                            break # æ¢å¤å¤±è´¥ï¼Œè·³å‡ºé‡è¯•
                    else:
                        log.error(f"Max retries reached or strict mode is on. Segment {i} has failed permanently.")
                        if self.strict_mode:
                            raise e # ä¸¥æ ¼æ¨¡å¼ä¸‹ç›´æ¥æŠ›å‡ºå¼‚å¸¸
                        result = None # éä¸¥æ ¼æ¨¡å¼ä¸‹æ ‡è®°å¤±è´¥
                        break # è·³å‡ºé‡è¯•
            
            segment_results.append(result)

        self.combine_segments(segment_results, true_audio_duration)
        
        print(f"\nâœ… Video composition complete: {self.output_video_path}")