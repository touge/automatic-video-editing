import sys
import subprocess
import os
from pathlib import Path
from typing import Optional
from tqdm import tqdm
import re
import torch
from faster_whisper import WhisperModel
import yt_dlp
import fnmatch
import json

class SubtitlesProcessor:
    def __init__(self, url: str, proxy: str = None):
        self.url = url
        self.proxy = proxy
        self.video_id = self._extract_video_id(url)
        self.audio_path = None
        # self.nltk_data_path å’Œç›¸å…³æ–¹æ³•å·²ç§»é™¤
        # jieba å¯¼å…¥å·²ç§»é™¤ï¼Œå› ä¸ºä¸å†è¿›è¡Œå¤æ‚åˆ†å¥

    def _proxy_arg(self) -> list[str]:
        return ["--proxy", self.proxy] if self.proxy else []

    def download_platform_subtitles(self, output_dir: str, target_filename_base: str) -> Optional[str]:
        """
        å°è¯•ä»è§†é¢‘å¹³å°ä¸‹è½½å­—å¹•ï¼ŒæŒ‰ç…§ä¼˜å…ˆçº§ï¼šç®€ä½“ä¸­æ–‡ã€ç¹ä½“ä¸­æ–‡ã€è‹±æ–‡ã€‚
        ä¼˜å…ˆä¸‹è½½ SRT æ ¼å¼ï¼Œå¦‚æœåªæœ‰ VTT åˆ™ä¸‹è½½ VTT å¹¶è½¬æ¢ä¸º SRTã€‚
        """
        print("ğŸŒ å°è¯•ä»è§†é¢‘å¹³å°ä¸‹è½½å­—å¹•...")
        
        preferred_langs = ['zh-Hans', 'zh-Hant', 'en']
        target_format = 'srt'
        fallback_format = 'vtt'

        os.makedirs(output_dir, exist_ok=True)

        try:
            ydl_info_opts = {
                'skip_download': True,
                'quiet': True,
                'proxy': self.proxy if self.proxy else None,
            }
            with yt_dlp.YoutubeDL(ydl_info_opts) as ydl_info:
                info_dict = ydl_info.extract_info(self.url, download=False)

            available_subtitles = info_dict.get('subtitles', {})

            if not available_subtitles:
                print("  - å¹³å°æ²¡æœ‰å¯ç”¨å­—å¹•ã€‚")
                return None

            sub_lang_to_download = None
            needs_conversion = False

            for lang in preferred_langs:
                if lang in available_subtitles:
                    sub_lang_to_download = lang
                    if not any(s['ext'] == target_format for s in available_subtitles[lang]):
                        if any(s['ext'] == fallback_format for s in available_subtitles[lang]):
                            needs_conversion = True
                    break
            
            if not sub_lang_to_download:
                print(f"  - æœªèƒ½æ‰¾åˆ°ç¬¦åˆä¼˜å…ˆçº§çš„å­—å¹• ({preferred_langs})ã€‚")
                return None

            sub_format_to_request = fallback_format if needs_conversion else target_format
            
            yt_dlp_command = [
                sys.executable, "-m", "yt_dlp",
                "--skip-download", "--write-subs",
                "--sub-langs", sub_lang_to_download,
                "--sub-format", sub_format_to_request,
                "-o", os.path.join(output_dir, f"{self.video_id}.%(ext)s"),
                self.url
            ]
            if self.proxy:
                yt_dlp_command.extend(["--proxy", self.proxy])

            subprocess.run(yt_dlp_command, check=True, capture_output=True, text=True, errors='replace')
            
            found_subtitle_path = None
            
            # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
            downloaded_sub_ext = fallback_format if needs_conversion else target_format
            search_pattern = f"{self.video_id}*.{sub_lang_to_download}.{downloaded_sub_ext}"
            
            for filename in fnmatch.filter(os.listdir(output_dir), search_pattern):
                found_path = Path(os.path.join(output_dir, filename))
                if found_path.exists() and found_path.stat().st_size > 0:
                    if needs_conversion:
                        srt_path = found_path.with_suffix('.srt')
                        try:
                            self._convert_vtt_to_srt(str(found_path), str(srt_path))
                            found_subtitle_path = srt_path
                        except Exception as e:
                            print(f"  âŒ VTTè½¬æ¢SRTå¤±è´¥: {e}")
                            continue
                    else:
                        found_subtitle_path = found_path
                    break

            if found_subtitle_path:
                final_srt_path = Path(output_dir) / f"{target_filename_base}.srt"
                if found_subtitle_path.resolve() != final_srt_path.resolve():
                     # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                    if os.path.exists(final_srt_path):
                        os.remove(final_srt_path)
                    os.rename(found_subtitle_path, final_srt_path)
                print(f"  âœ… æˆåŠŸä¸‹è½½å¹¶ä¿å­˜å­—å¹•: {final_srt_path}")
                return str(final_srt_path)
            else:
                print(f"  âš ï¸ yt-dlp æŠ¥å‘ŠæˆåŠŸï¼Œä½†æœªèƒ½æ‰¾åˆ°åŒ¹é…çš„å­—å¹•æ–‡ä»¶ã€‚")
                return None

        except subprocess.CalledProcessError as e:
            print(f"âŒ yt-dlp å‘½ä»¤è¡Œæ‰§è¡Œå¤±è´¥: {e.stderr}")
        except yt_dlp.utils.DownloadError as e:
            print(f"âŒ yt-dlp åœ¨è·å–ä¿¡æ¯æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¹³å°å­—å¹•æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        
        return None

    def _convert_vtt_to_srt(self, vtt_path: str, srt_path: str):
        """
        ä½¿ç”¨ ffmpeg å°† VTT å­—å¹•æ–‡ä»¶è½¬æ¢ä¸º SRT æ ¼å¼ã€‚
        """
        try:
            ffmpeg_command = ['ffmpeg', '-y', '-i', vtt_path, srt_path]
            subprocess.run(ffmpeg_command, check=True, capture_output=True, text=True)
            print(f"  âœ… VTTæ‰‹åŠ¨è½¬æ¢ä¸ºSRTæˆåŠŸ: {srt_path}")
            os.remove(vtt_path)
        except subprocess.CalledProcessError as e:
            print(f"  âŒ FFmpegæ‰‹åŠ¨è½¬æ¢VTTå¤±è´¥ã€‚stdout: {e.stdout}, stderr: {e.stderr}")
            raise
        except Exception as e:
            print(f"  âŒ æ‰‹åŠ¨è½¬æ¢VTTæ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            raise

    def _extract_video_id(self, url: str) -> str:
        # ç®€åŒ–è§†é¢‘ ID æå–ï¼Œé’ˆå¯¹ YouTube URL
        match = re.search(r'(?:v=|\/)([a-zA-Z0-9_-]{11})(?:&|\?)?.*', url)
        if match:
            return match.group(1)
        return "unknown_video" # æ— æ³•æå– ID æ—¶çš„å¤‡ç”¨

    def download_audio(self, output_dir: str, filename_base: str):
        """
        ä¸‹è½½è§†é¢‘éŸ³é¢‘ã€‚
        """
        print("ğŸµ Downloading audio...")
        os.makedirs(output_dir, exist_ok=True)
        
        # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾ä¸€ä¸ªä»»åŠ¡åªå¤„ç†ä¸€ä¸ªéŸ³é¢‘ï¼Œæ‰€ä»¥ä¸ä¸¥æ ¼æ£€æŸ¥åç¼€
        for f_name in os.listdir(output_dir):
            if f_name.startswith(filename_base) and any(f_name.endswith(ext) for ext in ['.m4a', '.webm', '.opus', '.mp3']):
                self.audio_path = os.path.join(output_dir, f_name)
                print(f"âœ… Audio file already exists: {self.audio_path}. Skipping download.")
                return

        # å¦‚æœéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™æ‰§è¡Œä¸‹è½½
        audio_output_path = os.path.join(output_dir, f"{filename_base}.%(ext)s")
        command = [
            sys.executable, "-m", "yt_dlp",
            "-x", "-f", "bestaudio", self.url,
            "-o", audio_output_path
        ]
        if self.proxy:
            command.extend(["--proxy", self.proxy])
        
        try:
            print("å°è¯•ä¸‹è½½éŸ³é¢‘ï¼Œä½¿ç”¨ yt-dlp -x -f bestaudio æ¨¡å¼...")
            subprocess.run(command, check=True)
            
            # ä¸‹è½½å®Œæˆåï¼Œå†æ¬¡æŸ¥æ‰¾å®é™…ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            newly_downloaded_audio_files = []
            for f_name in os.listdir(output_dir):
                if f_name.startswith(filename_base) and any(f_name.endswith(ext) for ext in ['.m4a', '.webm', '.opus', '.mp3']):
                    newly_downloaded_audio_files.append(os.path.join(output_dir, f_name))
            
            if newly_downloaded_audio_files:
                self.audio_path = newly_downloaded_audio_files[0]
                print(f"âœ… Audio downloaded to: {self.audio_path}")
            else:
                print(f"âš ï¸ æ— æ³•åœ¨ '{output_dir}' ç›®å½•ä¸­æ‰¾åˆ°ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ï¼Œä½† yt-dlp å‘½ä»¤æˆåŠŸå®Œæˆã€‚")
                self.audio_path = None

        except subprocess.CalledProcessError as e:
            print(f"âŒ ä¸‹è½½éŸ³é¢‘å¤±è´¥: {e.stderr}")
            self.audio_path = None
        except Exception as e:
            print(f"âŒ å‘ç”ŸæœªçŸ¥é”™è¯¯ï¼š{e}")
            self.audio_path = None

    def Otranscribe_with_whisper(self, model_dir: str):
        if not self.audio_path or not Path(self.audio_path).exists():
            print("âŒ Audio file not found for transcription.")
            return []

        print(f"ğŸ™ï¸ Transcribing audio with Faster Whisper model: {model_dir}...")
        try:
            # ç¡®ä¿ torch å·²å¯¼å…¥ä¸”å¯ç”¨ï¼Œå¦‚æœå¯ç”¨åˆ™ä½¿ç”¨ cuda
            model = WhisperModel(model_dir, device="cuda" if torch.cuda.is_available() else "cpu", compute_type="float16")
            segments, info = model.transcribe(self.audio_path, beam_size=5)
            print(f"âœ… Detected language: {info.language} with probability {info.language_probability:.4f}")
            
            segments_list = list(segments) # è½¬æ¢ä¸ºåˆ—è¡¨ä»¥ä¾¿å¤šæ¬¡è®¿é—®
            # print(f"DEBUG: Transcribed segments count: {len(segments_list)}") # è°ƒè¯•æ‰“å°å·²ç§»é™¤
            
            return segments_list
        except ImportError:
            print("âŒ PyTorch not found. Please install PyTorch for GPU support or ensure it's in your environment.")
            print("Falling back to CPU if possible, or try installing torch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 (for CUDA 11.8)")
            try:
                model = WhisperModel(model_dir, device="cpu", compute_type="int8") # CPU æ¨¡å¼å¯ä»¥ä½¿ç”¨ int8 ä¼˜åŒ–
                segments, info = model.transcribe(self.audio_path, beam_size=5)
                print(f"âœ… Detected language: {info.language} with probability {info.language_probability:.4f}")
                
                segments_list = list(segments)
                # print(f"DEBUG: Transcribed segments count (CPU fallback): {len(segments_list)}") # è°ƒè¯•æ‰“å°å·²ç§»é™¤
                
                return segments_list
            except Exception as e:
                print(f"âŒ Error during CPU transcription fallback: {e}")
                return []
        except Exception as e:
            print(f"âŒ Error during transcription: {e}")
            return []


    def OOtranscribe_with_whisper(self, model_dir: str):
        if not self.audio_path or not Path(self.audio_path).exists():
            print("âŒ Audio file not found for transcription.")
            return []

        print(f"ğŸ™ï¸ Transcribing audio with Faster Whisper model: {model_dir}...")
        try:
            model = WhisperModel(model_dir, device="cuda" if torch.cuda.is_available() else "cpu", compute_type="float16")
            
            # ä½¿ç”¨ tqdm æ¥æ˜¾ç¤ºè¿›åº¦æ¡
            # Faster Whisper çš„ transcribe æ–¹æ³•è¿”å›ä¸€ä¸ªè¿­ä»£å™¨
            # info å¯¹è±¡åŒ…å« duration_msï¼Œå¯ä»¥ç”¨æ¥ä¼°ç®—æ€»è¿›åº¦
            # ä¹Ÿå¯ä»¥ç›´æ¥è¿­ä»£ segmentsï¼Œtqdm ä¼šè‡ªåŠ¨è®¡ç®—è¿­ä»£æ¬¡æ•°
            
            # ç¬¬ä¸€æ¬¡è°ƒç”¨ transcribe æ—¶è·å– segments å’Œ info
            segments_generator, info = model.transcribe(self.audio_path, beam_size=5)
            print(f"âœ… Detected language: {info.language} with probability {info.language_probability:.4f}")
            
            segments_list = []
            # è·å–éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºè¿›åº¦æ¡
            total_audio_duration_ms = info.duration * 1000 
            
            # ä½¿ç”¨ tqdm åŒ…è£… segments è¿­ä»£å™¨ï¼Œå¹¶æ ¹æ®éŸ³é¢‘æ—¶é•¿æ˜¾ç¤ºè¿›åº¦
            # desc: è¿›åº¦æ¡æè¿°
            # total: è¿­ä»£çš„æ€»é‡ï¼Œè¿™é‡Œç”¨éŸ³é¢‘æ€»æ—¶é•¿
            # unit: å•ä½
            # unit_scale: å•ä½çš„ç¼©æ”¾æ¯”ä¾‹ (ms -> s)
            # bar_format: è‡ªå®šä¹‰è¿›åº¦æ¡æ ¼å¼ï¼Œæ˜¾ç¤ºå·²è½¬å½•æ—¶é•¿
            
            # è®°å½•èµ·å§‹æ—¶é—´ï¼Œç”¨äºè®¡ç®—å·²è½¬å½•æ—¶é•¿
            start_time_segment = 0.0

            # æ”¶é›† segments å¹¶åœ¨ tqdm ä¸­æ˜¾ç¤ºè¿›åº¦
            for segment in tqdm(segments_generator, 
                                desc="ğŸ”Š Transcribing Audio", 
                                unit="s", unit_scale=True,
                                total=total_audio_duration_ms / 1000, # total in seconds
                                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]"):
                
                segments_list.append(segment)
                # æ›´æ–°è¿›åº¦æ¡çš„å½“å‰å€¼ï¼Œä½¿ç”¨å½“å‰ segment çš„ç»“æŸæ—¶é—´
                tqdm.write_text(tqdm._instances[0], f"Processed: {self._format_timestamp(segment.end)}", end='\r') # æ˜¾ç¤ºå½“å‰è½¬å½•åˆ°å“ªä¸ªæ—¶é—´ç‚¹
                
            return segments_list
            
        except ImportError:
            print("âŒ PyTorch not found. Please install PyTorch for GPU support or ensure it's in your environment.")
            print("Falling back to CPU if possible, or try installing torch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 (for CUDA 11.8)")
            try:
                model = WhisperModel(model_dir, device="cpu", compute_type="int8")
                
                segments_generator, info = model.transcribe(self.audio_path, beam_size=5)
                print(f"âœ… Detected language: {info.language} with probability {info.language_probability:.4f}")
                
                segments_list = []
                total_audio_duration_ms = info.duration * 1000
                
                for segment in tqdm(segments_generator, 
                                    desc="ğŸ”Š Transcribing Audio (CPU)", 
                                    unit="s", unit_scale=True,
                                    total=total_audio_duration_ms / 1000,
                                    bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]"):
                    segments_list.append(segment)
                    tqdm.write_text(tqdm._instances[0], f"Processed: {self._format_timestamp(segment.end)}", end='\r')
                    
                return segments_list
            except Exception as e:
                print(f"âŒ Error during CPU transcription fallback: {e}")
                return []
        except Exception as e:
            print(f"âŒ Error during transcription: {e}")
            return []


    def transcribe_with_whisper(self, model_dir: str):
        if not self.audio_path or not Path(self.audio_path).exists():
            print("âŒ Audio file not found for transcription.")
            return []

        print(f"ğŸ™ï¸ Transcribing audio with Faster Whisper model: {model_dir}...")
        try:
            model = WhisperModel(model_dir, device="cuda" if torch.cuda.is_available() else "cpu", compute_type="float16")
            
            segments_generator, info = model.transcribe(self.audio_path, beam_size=5)
            print(f"âœ… Detected language: {info.language} with probability {info.language_probability:.4f}")
            
            segments_list = []
            
            # ç®€åŒ–è¿›åº¦æ˜¾ç¤ºï¼Œåªæ‰“å°å·²å¤„ç†çš„æ—¶é—´
            total_duration_seconds = info.duration # è·å–éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆç§’ï¼‰

            print("ğŸ”Š Transcription Progress:")
            
            # ä½¿ç”¨ tqdm ä½œä¸ºç®€å•çš„è¿­ä»£å™¨åŒ…è£…ï¼Œä¸å†ä¾èµ–å…¶å¤æ‚çš„ bar_format å’Œ write_text
            # ä»…é€šè¿‡è¿­ä»£ segment æ¥æ›´æ–°è¿›åº¦
            for i, segment in enumerate(segments_generator):
                segments_list.append(segment)
                
                # è®¡ç®—å·²å¤„ç†çš„ç™¾åˆ†æ¯”å’Œæ—¶é—´
                progress_percentage = (segment.end / total_duration_seconds) * 100 if total_duration_seconds > 0 else 0
                
                # æ‰“å°å·²è½¬å½•çš„æ—¶é•¿ï¼Œä½¿ç”¨ \r å›åˆ°è¡Œé¦–ï¼Œå®ç°åŠ¨æ€æ›´æ–°
                # flush=True ç¡®ä¿ç«‹å³æ‰“å°
                print(f"  Processed: {self._format_timestamp(segment.end)} / {self._format_timestamp(total_duration_seconds)} ({progress_percentage:.1f}%)", end='\r', flush=True)
            
            # è½¬å½•å®Œæˆåï¼Œæ‰“å°ä¸€ä¸ªç©ºè¡Œæˆ–å®Œæˆä¿¡æ¯ï¼Œæ¸…é™¤ä¸Šä¸€è¡Œçš„ \r æ•ˆæœ
            print("\nâœ… Transcription Complete!")
            
            return segments_list
            
        except ImportError:
            print("âŒ PyTorch not found. Please install PyTorch for GPU support or ensure it's in your environment.")
            print("Falling back to CPU if possible, or try installing torch: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 (for CUDA 11.8)")
            try:
                model = WhisperModel(model_dir, device="cpu", compute_type="int8")
                
                segments_generator, info = model.transcribe(self.audio_path, beam_size=5)
                print(f"âœ… Detected language: {info.language} with probability {info.language_probability:.4f}")
                
                segments_list = []
                total_duration_seconds = info.duration

                print("ğŸ”Š Transcription Progress (CPU Fallback):")
                for i, segment in enumerate(segments_generator):
                    segments_list.append(segment)
                    
                    progress_percentage = (segment.end / total_duration_seconds) * 100 if total_duration_seconds > 0 else 0
                    print(f"  Processed: {self._format_timestamp(segment.end)} / {self._format_timestamp(total_duration_seconds)} ({progress_percentage:.1f}%)", end='\r', flush=True)
                
                print("\nâœ… Transcription Complete (CPU Fallback)!")
                
                return segments_list
            except Exception as e:
                print(f"âŒ Error during CPU transcription fallback: {e}")
                return []
        except Exception as e:
            print(f"âŒ Error during transcription: {e}")
            return []

    def export_srt(self, segments: list, output_dir: str, filename: str) -> str:
        """
        å¯¼å‡ºä¸º SRT å­—å¹•æ–‡ä»¶ã€‚æ­¤æ–¹æ³•ä¿ç•™ï¼Œæ‚¨å¯ä»¥é€‰æ‹©ä½¿ç”¨æˆ–ä¸ä½¿ç”¨ã€‚
        """
        print("ğŸ“¤ Exporting subtitles to SRT file...")
        srt_path = os.path.join(output_dir, f"{filename}.srt")
        with open(srt_path, "w", encoding="utf-8") as f:
            for i, segment in enumerate(tqdm(segments, desc="ğŸ“„ Exporting SRT")):
                start_time = self._format_timestamp(segment.start)
                end_time = self._format_timestamp(segment.end)
                f.write(f"{i + 1}\n")
                f.write(f"{start_time} --> {end_time}\n")
                f.write(f"{segment.text.strip()}\n\n")
        print(f"âœ… SRT exported to: {srt_path}")
        return srt_path

    def _format_timestamp(self, seconds: float) -> str:
        milliseconds = int((seconds * 1000) % 1000)
        seconds_int = int(seconds)
        minutes = seconds_int // 60
        hours = minutes // 60
        return f"{hours:02}:{minutes % 60:02}:{seconds_int % 60:02},{milliseconds:03}"

    def export_line_txt(self, srt_file_path: str, output_dir: str):
        """
        å°† SRT æ–‡ä»¶è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ–‡ä»¶ï¼Œæ¯è¡Œä¸€ä¸ªå­—å¹•æ¡ç›®ï¼Œå»é™¤æ—¶é—´è½´å’Œåºå·ã€‚
        """
        print(f"ğŸ“– Starting to process SRT file for raw text export: {srt_file_path}")

        manuscript_lines = []
        try:
            with open(srt_file_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    # ç¡®ä¿åªæå–å®é™…çš„æ–‡æœ¬è¡Œï¼Œè·³è¿‡æ•°å­—å’Œæ—¶é—´æˆ³è¡Œ
                    if not line.isdigit() and "-->" not in line and line:
                        manuscript_lines.append(line)
        except FileNotFoundError:
            print(f"âŒ Error: SRT file not found at {srt_file_path}")
            return
        except Exception as e:
            print(f"âŒ Error reading SRT file {srt_file_path}: {e}")
            return

        if not manuscript_lines:
            print("âš ï¸ No text extracted from SRT file. Aborting raw text export.")
            return
        
        print("âš™ï¸ å°† SRT è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ–‡ä»¶ï¼Œå»é™¤æ—¶é—´è½´å¹¶æŒ‰è¡Œè¾“å‡º...")
        original_filename_base = Path(srt_file_path).stem
        manuscript_path = os.path.join(output_dir, f"{original_filename_base}_line.txt") # å‘½åä¸º _line.txt
        
        print(f"ğŸ“ Saving line-by-line text to: {manuscript_path}")
        with open(manuscript_path, "w", encoding="utf-8") as f:
            for line in manuscript_lines:
                f.write(line + "\n") # æ¯è¡Œä¸€ä¸ª SRT æ¡ç›®çš„æ–‡æœ¬
        print("âœ… Line-by-line text saved.")
